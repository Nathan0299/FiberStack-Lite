groups:
  - name: logging
    rules:
      # Log dropping alert
      - alert: LogsDropped
        expr: rate(log_dropped_total[5m]) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Logs being dropped due to sampling"
          description: "{{ $labels.service }} is dropping logs at {{ $value }}/sec"
      
      # DLQ filling up
      - alert: DLQFilling
        expr: dlq_size_bytes > 50000000  # 50MB
        labels:
          severity: critical
        annotations:
          summary: "Dead-letter queue approaching limit"
          description: "DLQ at {{ $value | humanize1024 }}, near 100MB cap"
      
      # ES ingestion slow
      - alert: ESIngestionSlow
        expr: histogram_quantile(0.99, rate(es_bulk_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Elasticsearch bulk ingestion slow"
          description: "p99 bulk latency is {{ $value }}s"
      
      # Missing trace IDs
      - alert: MissingTraceRatio
        expr: |
          rate(log_messages_total{trace_id="unknown"}[5m]) 
          / rate(log_messages_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High ratio of logs missing trace IDs"
          description: "{{ $value | humanizePercentage }} of logs have unknown trace_id"
      
      # Log surge per service
      - alert: LogSurge
        expr: rate(log_messages_total[5m]) > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Log volume spike detected"
          description: "{{ $labels.service }} logging at {{ $value }}/sec"
      
      # DLQ replay failures
      - alert: ReplayFailures
        expr: rate(dlq_replay_events_total{status="failed"}[5m]) > 0
        labels:
          severity: critical
        annotations:
          summary: "DLQ replay failing"
          description: "Failed to replay {{ $value }} events/sec"
